<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ReAgent Serving Platform (RASP) &mdash; ReAgent 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Continuous Integration" href="continuous_integration.html" />
    <link rel="prev" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> ReAgent
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">RASP (Not Actively Maintained)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-rasp">What is RASP?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installing-reagent">Installing ReAgent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#store-set-up">Store set-up</a></li>
<li class="toctree-l2"><a class="reference internal" href="#user-simulator">User simulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#makin-bacon">Makin’ bacon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#straight-outta-context">Straight Outta Context</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="continuous_integration.html">Continuous Integration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.core.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.gym.html">Gym</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.lite.html">Lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.mab.html">MAB</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.model_managers.html">Model Managers</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.model_utils.html">Model Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.net_builder.html">Net Builders</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.optimizer.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.prediction.html">Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.preprocessing.html">Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/reagent.workflow.html">Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">All Modules</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Others</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/facebookresearch/ReAgent">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ReAgent</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>ReAgent Serving Platform (RASP)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/rasp_tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="reagent-serving-platform-rasp">
<span id="rasp-tutorial"></span><h1>ReAgent Serving Platform (RASP)<a class="headerlink" href="#reagent-serving-platform-rasp" title="Permalink to this headline"></a></h1>
<p>Welcome to the ReAgent Serving Platform! This tutorial gets readers
familiar with reasoning at scale by building an artificial e-commerce
site.</p>
<section id="what-is-rasp">
<h2>What is RASP?<a class="headerlink" href="#what-is-rasp" title="Permalink to this headline"></a></h2>
<p>RASP is a set of scoring and ranking functions and a systematic way to
collect data and deploy models. A set of potential actions are input to
RASP and a ranked list of scores is output. The method for scoring and
ranking actions is called a decision plan. In this tutorial, we will
create several different decision plans and simulate user traffic to see
the results.</p>
</section>
<section id="installing-reagent">
<h2>Installing ReAgent<a class="headerlink" href="#installing-reagent" title="Permalink to this headline"></a></h2>
<p>Before beginning this tutorial, please install ReAgent by following
these instructions:
<a class="reference external" href="https://github.com/facebookresearch/ReAgent/blob/master/docs/installation.rst">https://github.com/facebookresearch/ReAgent/blob/master/docs/installation.rst</a></p>
</section>
<section id="store-set-up">
<h2>Store set-up<a class="headerlink" href="#store-set-up" title="Permalink to this headline"></a></h2>
<p>For this tutorial, we will be in charge of recommendations for
Pig-E-Barbeque, a pork e-store. Pig-E-Barbeque sells two products: Ribs
and Bacon. Our product manager has told us to optimize for clicks. Since
we are just starting out, we don’t know anything about our visitors, but
we know that bacon is delicious. We give bacon a score of 1.1 and ribs a
score of 1.0. (If we were optimizing for revenue, we could set the score
to the price, or we could have a custom scoring function.)</p>
<p>We also need to provide a ranking function that takes our scores and
decides which items to recommend. In Pig-E-Barbeque, we only have one
spot for recommendations, so the first item will be shown to visitors
and the second choice is discarded. If we use a greedy ranking function,
we will always show bacon (with it’s score of 1.1) and never show ribs
(with a score of 0.9). This means we will never know the true
performance of recommending ribs and can’t improve our system in the
future. This is known as the cold-start or explore-exploit problem
( <a class="reference external" href="https://arxiv.org/abs/1812.00116">https://arxiv.org/abs/1812.00116</a> ).</p>
<p>To avoid that problem, we will use the SoftmaxRanker, which will show
bacon 52% of the time and ribs 48% of the time. The SoftmaxRanker
operator is based on the softmax function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">e_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">e_x</span> <span class="o">/</span> <span class="n">e_x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]))</span>
<span class="go">[0.52497919 0.47502081]</span>
</pre></div>
</div>
<p>Here is the decision plan generator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">softmaxranker_decision_plan</span><span class="p">():</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">SoftmaxRanker</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Bacon&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;Ribs&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">DecisionPlanBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">set_root</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<p>And here is the generated decision plan:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;operators&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker_1&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_3&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;constants&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;double_value&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_3&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;map_double_value&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;Bacon&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span>
                    <span class="s2">&quot;Ribs&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;num_actions_to_choose&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;reward_function&quot;</span><span class="p">:</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reward_aggregator&quot;</span><span class="p">:</span> <span class="s2">&quot;sum&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="user-simulator">
<h2>User simulator<a class="headerlink" href="#user-simulator" title="Permalink to this headline"></a></h2>
<p>Because this isn’t a real store, we need a way to simulate users. Our
simulator has a few rules:</p>
<ol class="arabic simple">
<li><p>Visitors click on bacon recommendations 50% of the time</p></li>
<li><p>10% of visits are by rib lovers and the rest are regular visitors</p>
<ol class="arabic simple">
<li><p>Rib lovers click on rib recommendations 90% of the time</p></li>
<li><p>Regular visitors click on rib recommendations 10%</p></li>
</ol>
</li>
</ol>
<p>We will be using the built-in web service directly for this tutorial.
The simulator code can be found at:
serving/examples/ecommerce/customer_simulator.py</p>
</section>
<section id="makin-bacon">
<h2>Makin’ bacon<a class="headerlink" href="#makin-bacon" title="Permalink to this headline"></a></h2>
<p>In one terminal window, start the RP server:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ./serving/build/RaspCli --logtostderr
I1014 17:23:19.736086 457250240 DiskConfigProvider.cpp:10] READING CONFIGS FROM serving/examples/ecommerce/plans
I1014 17:23:19.738142 457250240 DiskConfigProvider.cpp:42] GOT CONFIG multi_armed_bandit.json AT serving/examples/ecommerce/plans/multi_armed_bandit.json
I1014 17:23:19.738286 457250240 DiskConfigProvider.cpp:46] Registered decision config: multi_armed_bandit.json
I1014 17:23:19.738932 457250240 DiskConfigProvider.cpp:42] GOT CONFIG contextual_bandit.json AT serving/examples/ecommerce/plans/contextual_bandit.json
I1014 17:23:19.739020 457250240 DiskConfigProvider.cpp:46] Registered decision config: contextual_bandit.json
I1014 17:23:19.739610 457250240 DiskConfigProvider.cpp:42] GOT CONFIG heuristic.json AT serving/examples/ecommerce/plans/heuristic.json
I1014 17:23:19.739682 457250240 DiskConfigProvider.cpp:46] Registered decision config: heuristic.json
I1014 17:23:19.739843 131715072 Server.cpp:58] STARTING SERVER
</pre></div>
</div>
<p>Then in another, run our simulator. The simulator will spawn many
threads and call RASP 1,000 times:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  python serving/examples/ecommerce/customer_simulator.py heuristic.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.363
Action Distribution: {&#39;Ribs&#39;: 471, &#39;Bacon&#39;: 529}
</pre></div>
</div>
<p>As expected, we recommend Bacon 52% of the time and Ribs 48% of the
time. We get an average reward (in this case, average # of clicks) of about 0.36.</p>
<p>This is our baseline performance, but can we do better? From the log, we
can see that more bacon recommendations were clicked on:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Ribs&quot;}]&#39; | grep &#39;&quot;reward&quot;:0.0&#39; | wc -l
    390 # Ribs not clicked
➜  cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Ribs&quot;}]&#39; | grep &#39;&quot;reward&quot;:1.0&#39; | wc -l
     88 # Ribs clicked
➜  cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Bacon&quot;}]&#39; | grep &#39;&quot;reward&quot;:1.0&#39; | wc -l
    266 # Bacon clicked
➜  cat /tmp/rasp_logging/log.txt | grep &#39;&quot;name&quot;:&quot;Bacon&quot;}]&#39; | grep &#39;&quot;reward&quot;:0.0&#39; | wc -l
    253 # Bacon not clicked
</pre></div>
</div>
<p>This makes sense since, from our simulator definition, most people
aren’t rib-lovers and only click on ribs 10% of the time. We can change
the decision plan to use a multi-armed bandit that will learn to show
bacon much more often. For this tutorial, we will use the UCB1 bandit
ranker. Passing this to the plan generator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ucb_decision_plan</span><span class="p">():</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">UCB</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;UCB1&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DecisionPlanBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">set_root</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<p>Generates this plan:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  cat serving/examples/ecommerce/plans/multi_armed_bandit.json
{
    &quot;operators&quot;: [
        {
            &quot;name&quot;: &quot;UCB_1&quot;,
            &quot;op_name&quot;: &quot;Ucb&quot;,
            &quot;input_dep_map&quot;: {
                &quot;method&quot;: &quot;constant_2&quot;,
                &quot;batch_size&quot;: &quot;constant_3&quot;
            }
        }
    ],
    &quot;constants&quot;: [
        {
            &quot;name&quot;: &quot;constant_2&quot;,
            &quot;value&quot;: {
                &quot;string_value&quot;: &quot;UCB1&quot;
            }
        },
        {
            &quot;name&quot;: &quot;constant_3&quot;,
            &quot;value&quot;: {
                &quot;int_value&quot;: 16
            }
        }
    ],
    &quot;num_actions_to_choose&quot;: 1,
    &quot;reward_function&quot;: &quot;reward&quot;,
    &quot;reward_aggregator&quot;: &quot;sum&quot;
}
</pre></div>
</div>
<p>Running with this new plan gives:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  python serving/examples/ecommerce/customer_simulator.py multi_armed_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.447
Action Distribution: {&#39;Ribs&#39;: 184, &#39;Bacon&#39;: 816}
</pre></div>
</div>
<p>This is already better than our previous score of 0.363. While we were
running, the bandit was learning and adapting the scores. Let’s run
again:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  python serving/examples/ecommerce/customer_simulator.py multi_armed_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.497
Action Distribution: {&#39;Bacon&#39;: 926, &#39;Ribs&#39;: 74}
</pre></div>
</div>
<p>So the new ranker chooses bacon more often and gets more reward on
average than our first plan. If we keep running, eventually the model
will stop exploring the Ribs action and the average reward will approach
50% (which is the chance of a reward that we set in our simulator).</p>
</section>
<section id="straight-outta-context">
<h2>Straight Outta Context<a class="headerlink" href="#straight-outta-context" title="Permalink to this headline"></a></h2>
<p>While running the store, our data scientist has discovered a way to
figure out who is a rib-lover. Now we can pass a context feature which
is 1 when the visitor is a rib lover and 0 otherwise. In this section we
will train a contextual bandit that learns to show ribs to rib lovers
and bacon to everyone else.</p>
<p>As we specified in our config, RP has been writing a log of visits and
feedback to a file. We can input this file with a training config to
ReAgent to train a contextual bandit model. First, let’s clear our
training data and start over by sending a SIGINT (control-c) to our
instance of RaspCli:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>…
I1014 17:45:36.613893 6602752 Server.cpp:58] STARTING SERVER
^C
➜  rm /tmp/rasp_logging/log.txt
➜  ./serving/build/RaspCli --logtostderr
I1014 17:48:49.674149 144418240 DiskConfigProvider.cpp:10] READING CONFIGS FROM serving/examples/ecommerce/plans
I1014 17:48:49.678155 144418240 DiskConfigProvider.cpp:42] GOT CONFIG multi_armed_bandit.json AT serving/examples/ecommerce/plans/multi_armed_bandit.json
I1014 17:48:49.679606 144418240 DiskConfigProvider.cpp:46] Registered decision config: multi_armed_bandit.json
I1014 17:48:49.680496 144418240 DiskConfigProvider.cpp:42] GOT CONFIG contextual_bandit.json AT serving/examples/ecommerce/plans/contextual_bandit.json
I1014 17:48:49.680778 144418240 DiskConfigProvider.cpp:46] Registered decision config: contextual_bandit.json
I1014 17:48:49.682201 144418240 DiskConfigProvider.cpp:42] GOT CONFIG heuristic.json AT serving/examples/ecommerce/plans/heuristic.json
I1014 17:48:49.682344 144418240 DiskConfigProvider.cpp:46] Registered decision config: heuristic.json
I1014 17:48:49.682667 65638400 Server.cpp:58] STARTING SERVER
</pre></div>
</div>
<p>Now let’s run the heuristic model a few times to generate enough data
(this may take a few minutes). At the end there should be 10000 samples
(we can verify this with the wc command):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  for run in {1..10}; do python serving/examples/ecommerce/customer_simulator.py heuristic.json; done
0
200
...
900
Average reward: 0.36
Action Distribution: {&#39;Bacon&#39;: 516, &#39;Ribs&#39;: 484}
➜  wc -l /tmp/rasp_logging/log.txt
   10000 /tmp/rasp_logging/log.txt
</pre></div>
</div>
<p>RASP’s logging format and the ReAgent models’ input format is slightly
different. Fortunately, there’s a tool to convert from one to the other:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  python serving/scripts/rasp_to_model.py /tmp/rasp_logging/log.txt /tmp/input_df.pkl
 ...
 INFO:__main__:           ds               mdp_id  sequence_number    state_features action  reward  action_probability possible_actions          metrics
 0  2019-01-01  1287515757457242569                0  {0: 0.0, 1: 1.0}   Ribs     0.0            0.475021    [Bacon, Ribs]  {&#39;reward&#39;: 0.0}
 1  2019-01-01 -1441171268272508658                0  {0: 0.0, 1: 1.0}   Ribs     0.0            0.475021    [Bacon, Ribs]  {&#39;reward&#39;: 0.0}
 2  2019-01-01  -267723109738500267                0  {0: 0.0, 1: 1.0}  Bacon     1.0            0.524979    [Bacon, Ribs]  {&#39;reward&#39;: 1.0}
 3  2019-01-01  7619952535038766490                0  {0: 0.0, 1: 1.0}   Ribs     0.0            0.475021    [Bacon, Ribs]  {&#39;reward&#39;: 0.0}
 4  2019-01-01 -2393212434904546228                0  {0: 0.0, 1: 1.0}  Bacon     0.0            0.524979    [Bacon, Ribs]  {&#39;reward&#39;: 0.0}
</pre></div>
</div>
<p>Since we are using the contextual bandit or RL model, we need to build a
timeline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># Set the config
➜  export CONFIG=serving/examples/ecommerce/training/contextual_bandit.yaml

# First clean up derby database from last run
➜  rm -Rf spark-warehouse derby.log metastore_db preprocessing/spark-warehouse preprocessing/metastore_db preprocessing/derby.log

# Run timeline operator
➜  ./reagent/workflow/cli.py run reagent.workflow.gym_batch_rl.timeline_operator &quot;$CONFIG&quot;
</pre></div>
</div>
<p>The <a class="reference external" href="https://click.palletsprojects.com/en/7.x/">Click</a> command submits a Spark job that uploads the timeline table to Hive.
Now we can train the contextual bandit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  ./reagent/workflow/cli.py run reagent.workflow.training.identify_and_train_network &quot;$CONFIG&quot;
...
I0524 112136.208 model_manager.py:213] Saved torchscript model to model_1590344496.torchscript
</pre></div>
</div>
<p>At this point, we have a model saved at <code class="docutils literal notranslate"><span class="pre">model_*.torchscript</span></code>. We
are going to combine this scoring model with an Softmax ranker. The
ranker chooses the best actions most of the time, but rarely
chooses other actions to explore:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;operators&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoringOp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoring&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;model_id&quot;</span><span class="p">,</span>
                <span class="s2">&quot;snapshot_id&quot;</span><span class="p">:</span> <span class="s2">&quot;snapshot_id&quot;</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRankerOp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;op_name&quot;</span><span class="p">:</span> <span class="s2">&quot;SoftmaxRanker&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_dep_map&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="s2">&quot;ActionValueScoringOp&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;constants&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;model_id&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;int_value&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;snapshot_id&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;int_value&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;constant_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;double_value&quot;</span><span class="p">:</span> <span class="mf">0.001</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;num_actions_to_choose&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;reward_function&quot;</span><span class="p">:</span> <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reward_aggregator&quot;</span><span class="p">:</span> <span class="s2">&quot;sum&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The “model_id” and “snapshot_id” tell us where to find the model. Let’s
put the model there so we can find it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  mkdir -p /tmp/0
➜  cp model_*.torchscript /tmp/0/0
</pre></div>
</div>
<p>Let’s run with our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>➜  python serving/examples/ecommerce/customer_simulator.py contextual_bandit.json
0
200
100
400
300
500
600
700
800
900
Average reward: 0.52
Action Distribution: {&#39;Bacon&#39;: 883, &#39;Ribs&#39;: 117}
</pre></div>
</div>
<p>Nice! We have a reward higher than 50%, which is the click-through-rate
for bacon. This means that we must be getting most of the rib lovers. In
case you were curious, the best possible score is (0.9*0.5 + 0.1*0.9)
== 0.54. We still have some exploration in our new plan so we won’t get
exactly 0.54 even with many iterations, but we need that exploration to
generate an even better model next time when we learn more about our
customers.</p>
<p>All of the decisions made so far have been pointwise: we don’t consider
repeat visitors. ReAgent can also optimize for long-term value in
sequential decisions using reinforcement learning, but that is out of
the scope of this starting tutorial.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage.html" class="btn btn-neutral float-left" title="Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="continuous_integration.html" class="btn btn-neutral float-right" title="Continuous Integration" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Meta Platforms, Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>